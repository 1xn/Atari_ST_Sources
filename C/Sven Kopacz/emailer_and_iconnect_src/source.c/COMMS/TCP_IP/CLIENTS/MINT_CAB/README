This is version 1.64!
Changes:

* Better handling for the url-info caching.

* I made a mistake when I read the HTTP/1.0 spec. Apparently it actually
included the draft 1.1 spec. So we comply with that too. A happy accident.
:)

* Improvements in file-handling, and error-reporting.

* Caching completely rewritten (again).

* URL fetching simplified (as opposed to the monster that it had become)

------Notes for 1.51-------------
* Completely rearranged the source. There are now two .c files and 2.h
files. I've got a few 'external' viewers lined up and I wanted to thieve
some routines. :)
* I got a hold of the HTML/1.0 HTTP/1.0 specification today (via CAB), and
madly recoded to make it compliant. To that end:
- Now recognizes all three official date/time formats (including the 'one
you don't use')
- Handles v1.0 redirections...at least this _seems_ to work. Also tries
hard to automate v0.9 redirections (which were never intended to be
automatic)
- Understands v1.0 error/success response codes (at least in form).

* Modifed get_url_info() again. KEEPINFO is defined in init.c (near the
top). It sets the number of discrete URL's that get_url_info() will cache
the info for. Therefore,  setting it to 50 (the current default) keeps the
URL info for the last 50 different URL's accessed. This is very much like
the way that many other browsers do it, except that they don't have a hard
limit. [BTW, KEEPINFO may be set to 0 to turn this feature off entirely]

* Added socket-forcing to the timeout code. As timeouts occur, a carriage
return (well, actually it's a line-feed) will be written to the socket.
Often, in lagging, synch-lost or otherwise delayed TCP connections this
will assist the process of getting the end-to-end transmission running
again.

* Umm. Added -fforce-mem and -fforce-addr to the compile-time options.
* Err.. lots of other stuff.

---Notes for 1.33-----------
Changes:
* Find bug. Fix bug. While bugs found, repeat.
* More sanity checking. Better timeouts.
* A cheat in get_url_info(). If the info requested is for the same url as
the last call to the routine, then the information is supplied without a
lookup on the assumption (perhaps false) that the page hasn't changed.
This _dramatically_ speeds up pages like Yahoo with it's multiple 'New!'
icons.

---Notes for 1.31-----------
Some better error handling for dead sockets has appeared, but the system
still jams up at certain points. Perhaps I'm losing a file-handle now and
again.

Whatever. There are some pages that _will_ _not_ load without hanging CAB.
I don't know if this is a problem with CAB or the Overlay, but they are
fairly intensive pages.


----------------------------------------------
Disclaimer: If you want to blame someone other than yourself for loss or
damages, then go and use someone else's software, you can't use this.

